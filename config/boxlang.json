{
    "modules": {
        "bxai" :{
            "settings" : {
                // The default provider LLM AI: openai, deepseek, etc
                "provider" : "openrouter",
                // The default request params to use when calling a provider, any provider
                // Ex: { temperature: 0.5, max_tokens: 100, model: "gpt-3.5-turbo" }
                // gpt-oss-120b
                "defaultParams" : {
                    //"model": "stepfun/step-3.5-flash"
					//"model" : "openrouter/free"
					"model" : "openrouter/auto"
                },
                // The default memory to use when calling aiMemory()
                "memory" : {
                    "provider" : "window",
                    "config" : {}
                },
                // This is used to configure default options and parameters for a specific provider
                // The name of the key is the provider name, each provider can have its own params and options
                "providers" : {
                    "openai" : {
                    	"params" : {
							"model": "gpt-3.5-turbo"
						}
                    },
					"claude" : {
						"params": {
							"model": "claude-sonnet-4-5"
						}
					}
                },
                // The default timeout of the ai requests
                "timeout" : 30,
                // If true, the AI request will be logged into the ai.log
                "logRequest" : false,
                // If true, the AI request will be logged to the console
                "logRequestToConsole" : true,
                // If true, the AI response will be logged into the ai.log
                "logResponse" : false,
                // If true, the AI response will be logged to the console
                "logResponseToConsole" : false,
                // The default return format of the AI response: single, all, raw
                "returnFormat" : "single"
            }
        }
    }
}